<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Ka Ian Chan</title>
    <link>https://kaian9804.github.io/post/</link>
    <description>Recent content in Posts on Ka Ian Chan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Oct 2023 18:22:08 +0800</lastBuildDate><atom:link href="https://kaian9804.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Concolutional Neural Networks (CNNs)</title>
      <link>https://kaian9804.github.io/post/04_cnn/</link>
      <pubDate>Wed, 11 Oct 2023 18:22:08 +0800</pubDate>
      
      <guid>https://kaian9804.github.io/post/04_cnn/</guid>
      <description>Architecture Convolution Layer: Can separates and identifies the various features of images (= feature extraction)
Pooling Layer: Summarise the features presents in a region of the feature map generated by a convoution layer (= reduce dimensions)
Fully-Connected Layer: Use the output from the convolution process, and predicts the class of the image based on the features extracted in previous stages. It can only handle one-dimensions layer.
Other information Input shape should represent data reshaped as an image</description>
    </item>
    
    <item>
      <title>Long Short-Term Memory (LSTM)</title>
      <link>https://kaian9804.github.io/post/03_lstm/</link>
      <pubDate>Wed, 11 Oct 2023 10:03:00 +0800</pubDate>
      
      <guid>https://kaian9804.github.io/post/03_lstm/</guid>
      <description>Long Short-Term Memory (LSTM) Architecture LSTM uses gates to deal with calcualtions. It is used with time series data, but tabular is not time series data.
Forget Gate: Will forget the useless information (no longer needed)
Learn Gate: Combine the Event (= current input) and STM together, so the recently learnt necessary information (from STM) can apply to the current input
Remember Gate: Have not forget the LTM information, STM and Event are combined in remember gate which work as updated LTM</description>
    </item>
    
    <item>
      <title>Long Short-Term Memory (LSTM)</title>
      <link>https://kaian9804.github.io/post/999_template/</link>
      <pubDate>Wed, 11 Oct 2023 10:03:00 +0800</pubDate>
      
      <guid>https://kaian9804.github.io/post/999_template/</guid>
      <description> </description>
    </item>
    
    <item>
      <title>Coding for Multi-layer Perceptron (MLP)</title>
      <link>https://kaian9804.github.io/post/02_mlp/</link>
      <pubDate>Tue, 10 Oct 2023 00:42:00 +0800</pubDate>
      
      <guid>https://kaian9804.github.io/post/02_mlp/</guid>
      <description>1. Loading the Library from numpy import loadtxtfrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import BatchNormalization, Dense 2. Loading Dataset df = loadtxt(&amp;#34;dataset.csv&amp;#34;, delimiter=&amp;#39;,&amp;#39;) 3. Spliting Features and label For example, the data includes 5 features and 1 label.
x = df[:, 0:5]y = df[:, 5] 4. Define Neural Network Architecture model = Sequential()model.add(Dense(12, input_dim=5, activation=&amp;#39;relu&amp;#39;))model.add(BatchNormalization())model.add(Dense(8, activation=&amp;#39;relu&amp;#39;))model.add(BatchNormalization())model.add(Dense(1, activation=&amp;#39;sigmoid&amp;#39;)) 5. Compile the Model model.compile(loss = &amp;#39;binary_crossentropy&amp;#39;, # this is a binary problemoptimizer = &amp;#39;adam&amp;#39;,metrics = [&amp;#39;accuracy&amp;#39;]) 6.</description>
    </item>
    
    <item>
      <title>Feature Engineering with Stepwise Regression</title>
      <link>https://kaian9804.github.io/post/01_stepwise_regression/</link>
      <pubDate>Sun, 08 Oct 2023 21:16:00 +0800</pubDate>
      
      <guid>https://kaian9804.github.io/post/01_stepwise_regression/</guid>
      <description>When I was studying statistics, I noticed an algorithm called &amp;ldquo;stepwise regression&amp;rdquo;. Generally, this is a method that ranks features based on their importances and finds out how important each feature is to the prediction. The following coding will show the process of finding the features importances. (Assumed that this is a binary classification) Import the tools import pandas as pd from sklearn.preprocessing import MinMaxScaler from sklearn.preprocessing import LabelEncoder from</description>
    </item>
    
    <item>
      <title>Creating my Website</title>
      <link>https://kaian9804.github.io/post/00_my_web/</link>
      <pubDate>Sun, 08 Oct 2023 01:10:00 +0800</pubDate>
      
      <guid>https://kaian9804.github.io/post/00_my_web/</guid>
      <description>I want a website I wanted to have my own personal website for a long time. I have tried to create a website many times. I tried to have my own website on 000webhostapp, hostinger and gihub with HTML and CSS, but these designs are usually so simple and unsatisfied for me. Now I really want to build a new one! I am building this website with Hugo. This is</description>
    </item>
    
  </channel>
</rss>
